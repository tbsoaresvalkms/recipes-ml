{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Construindo uma Rede Neural Artificial no TensorFlow 2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbsoaresvalkms/recipes-ml/blob/master/tensorflow2_0/Construindo_uma_Rede_Neural_Artificial_no_TensorFlow_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJr4nMgyb9oS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png\" />\n",
        "  Image source: https://www.kaggle.com/\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVF9I9v6Zipb",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 1: Instalando o TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6fShx3Za4O",
        "colab_type": "code",
        "outputId": "80fe9e12-9a9a-426e-aa59-e364d5bc3378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.17.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.6)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjlnjPnjWYFw",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 2: Importando as bibliotecas e a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt0-hrch6rZw",
        "colab_type": "code",
        "outputId": "38eb699c-ad03-4c43-b883-1a2e2e1ef1b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vv9AXUnZW78",
        "colab_type": "code",
        "outputId": "be51a0a2-7ccd-4c67-a398-cfd57dd9886f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2OiUS-kWkJU",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 3: Pré-processamento\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfoFiEEXYj1",
        "colab_type": "text"
      },
      "source": [
        "### Carregando a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lCgz6UC8pKT",
        "colab_type": "code",
        "outputId": "4964dfa5-67e9-47c5-8629-8e5c46dbdc2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Noa1UZKpCDfA",
        "colab_type": "code",
        "outputId": "eb947062-5a98-4a98-9a6c-97f072ba4515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFr_QN4CIol",
        "colab_type": "code",
        "outputId": "668d3df7-9246-4562-99df-4eb3aab87274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64KujWQOCTOw",
        "colab_type": "code",
        "outputId": "fe4f321c-9c72-4d22-c8a9-db2a5d12c2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjw0rIOICV2E",
        "colab_type": "code",
        "outputId": "4a70dae6-1c2f-45b8-ed57-3b4faf6d2864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go31KdXnktlV",
        "colab_type": "text"
      },
      "source": [
        "0 0 0 0 0 1 0 0 0 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYxeEHzDXdSs",
        "colab_type": "text"
      },
      "source": [
        "### Normalizando as imagens\n",
        "\n",
        "Dividimos cada pixel das imagens das bases de treinamento e teste, utilizando o maior valor que é 255\n",
        "\n",
        "Com isso, cada pixel estará na faixa entre 0 e 1. Dessa forma, a rede neural vai treinar mais rápida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvWzsB3G9IU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo--rpqo9ZtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxhA1vvICcgj",
        "colab_type": "code",
        "outputId": "23a1d1ac-c95c-4cd4-f80f-4e9428fc57f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
              "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
              "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
              "        0.        , 0.        , 0.01176471],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
              "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04705882, 0.03921569, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
              "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
              "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
              "        0.50980392, 0.28235294, 0.05882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
              "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
              "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
              "        0.34509804, 0.6745098 , 0.25882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
              "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
              "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
              "        0.76862745, 0.89803922, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
              "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
              "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
              "        0.96078431, 0.67843137, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
              "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
              "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
              "        0.95294118, 0.79215686, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
              "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
              "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
              "        0.77254902, 0.81960784, 0.20392157],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
              "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
              "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
              "        0.46666667, 0.65490196, 0.21960784],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
              "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
              "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
              "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
              "        0.81960784, 0.36078431, 0.        ],\n",
              "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
              "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
              "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
              "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
              "        1.        , 0.30196078, 0.        ],\n",
              "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
              "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
              "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
              "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
              "        0.95686275, 0.62352941, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
              "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
              "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
              "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
              "        0.93333333, 0.84313725, 0.        ],\n",
              "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
              "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
              "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
              "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
              "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
              "        0.90980392, 0.96470588, 0.        ],\n",
              "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
              "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
              "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
              "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
              "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
              "        0.89411765, 0.88235294, 0.        ],\n",
              "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
              "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
              "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
              "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
              "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
              "        0.87843137, 0.89803922, 0.11372549],\n",
              "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
              "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
              "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
              "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
              "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
              "        0.86666667, 0.90196078, 0.2627451 ],\n",
              "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
              "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
              "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
              "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
              "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
              "        0.80392157, 0.80784314, 0.45098039],\n",
              "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
              "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
              "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
              "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
              "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
              "        0.69411765, 0.82352941, 0.36078431],\n",
              "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
              "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
              "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
              "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
              "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
              "        0.84705882, 0.66666667, 0.        ],\n",
              "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
              "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
              "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
              "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
              "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
              "        0.22745098, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBacLmGIX0Es",
        "colab_type": "text"
      },
      "source": [
        "### Remodelando (reshaping) a base de dados\n",
        "\n",
        "Como estamos trabalhando com uma rede neural densa, mudamos a dimensão das bases de dados para ficarem no formato de vetor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR6UvdpDChqJ",
        "colab_type": "code",
        "outputId": "d8d4fa37-0f63-4f8a-cd1a-6e96aaecde35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tao7pom-grn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Como a dimensão de cada imagem é 28x28, mudamos toda a base de dados para o formato [-1 (todos os elementos), altura * largura]\n",
        "X_train = X_train.reshape(-1, 28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9MbMrg9-kr_",
        "colab_type": "code",
        "outputId": "313460a7-265a-4b0e-f037-a37c77352b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluazdGHEx2w",
        "colab_type": "code",
        "outputId": "991da36e-e291-44a1-d146-679ac8099d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
              "       0.28627451, 0.        , 0.        , 0.00392157, 0.01568627,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
              "       0.        , 0.14117647, 0.53333333, 0.49803922, 0.24313725,\n",
              "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.01176471, 0.01568627, 0.        , 0.        , 0.01176471,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "       0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
              "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.60784314, 0.9254902 , 0.81176471,\n",
              "       0.69803922, 0.41960784, 0.61176471, 0.63137255, 0.42745098,\n",
              "       0.25098039, 0.09019608, 0.30196078, 0.50980392, 0.28235294,\n",
              "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.        , 0.27058824,\n",
              "       0.81176471, 0.8745098 , 0.85490196, 0.84705882, 0.84705882,\n",
              "       0.63921569, 0.49803922, 0.4745098 , 0.47843137, 0.57254902,\n",
              "       0.55294118, 0.34509804, 0.6745098 , 0.25882353, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
              "       0.00392157, 0.        , 0.78431373, 0.90980392, 0.90980392,\n",
              "       0.91372549, 0.89803922, 0.8745098 , 0.8745098 , 0.84313725,\n",
              "       0.83529412, 0.64313725, 0.49803922, 0.48235294, 0.76862745,\n",
              "       0.89803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.71764706, 0.88235294, 0.84705882, 0.8745098 , 0.89411765,\n",
              "       0.92156863, 0.89019608, 0.87843137, 0.87058824, 0.87843137,\n",
              "       0.86666667, 0.8745098 , 0.96078431, 0.67843137, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
              "       0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
              "       0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
              "       0.95294118, 0.79215686, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
              "       0.04705882, 0.85882353, 0.8627451 , 0.83137255, 0.85490196,\n",
              "       0.75294118, 0.6627451 , 0.89019608, 0.81568627, 0.85490196,\n",
              "       0.87843137, 0.83137255, 0.88627451, 0.77254902, 0.81960784,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.02352941, 0.        , 0.38823529, 0.95686275,\n",
              "       0.87058824, 0.8627451 , 0.85490196, 0.79607843, 0.77647059,\n",
              "       0.86666667, 0.84313725, 0.83529412, 0.87058824, 0.8627451 ,\n",
              "       0.96078431, 0.46666667, 0.65490196, 0.21960784, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.01568627, 0.        ,\n",
              "       0.        , 0.21568627, 0.9254902 , 0.89411765, 0.90196078,\n",
              "       0.89411765, 0.94117647, 0.90980392, 0.83529412, 0.85490196,\n",
              "       0.8745098 , 0.91764706, 0.85098039, 0.85098039, 0.81960784,\n",
              "       0.36078431, 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.01568627, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.92941176,\n",
              "       0.88627451, 0.85098039, 0.8745098 , 0.87058824, 0.85882353,\n",
              "       0.87058824, 0.86666667, 0.84705882, 0.8745098 , 0.89803922,\n",
              "       0.84313725, 0.85490196, 1.        , 0.30196078, 0.        ,\n",
              "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
              "       0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
              "       0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
              "       0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
              "       0.95686275, 0.62352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156863,\n",
              "       0.41960784, 0.74117647, 0.89411765, 0.8627451 , 0.87058824,\n",
              "       0.85098039, 0.88627451, 0.78431373, 0.80392157, 0.82745098,\n",
              "       0.90196078, 0.87843137, 0.91764706, 0.69019608, 0.7372549 ,\n",
              "       0.98039216, 0.97254902, 0.91372549, 0.93333333, 0.84313725,\n",
              "       0.        , 0.        , 0.22352941, 0.73333333, 0.81568627,\n",
              "       0.87843137, 0.86666667, 0.87843137, 0.81568627, 0.8       ,\n",
              "       0.83921569, 0.81568627, 0.81960784, 0.78431373, 0.62352941,\n",
              "       0.96078431, 0.75686275, 0.80784314, 0.8745098 , 1.        ,\n",
              "       1.        , 0.86666667, 0.91764706, 0.86666667, 0.82745098,\n",
              "       0.8627451 , 0.90980392, 0.96470588, 0.        , 0.01176471,\n",
              "       0.79215686, 0.89411765, 0.87843137, 0.86666667, 0.82745098,\n",
              "       0.82745098, 0.83921569, 0.80392157, 0.80392157, 0.80392157,\n",
              "       0.8627451 , 0.94117647, 0.31372549, 0.58823529, 1.        ,\n",
              "       0.89803922, 0.86666667, 0.7372549 , 0.60392157, 0.74901961,\n",
              "       0.82352941, 0.8       , 0.81960784, 0.87058824, 0.89411765,\n",
              "       0.88235294, 0.        , 0.38431373, 0.91372549, 0.77647059,\n",
              "       0.82352941, 0.87058824, 0.89803922, 0.89803922, 0.91764706,\n",
              "       0.97647059, 0.8627451 , 0.76078431, 0.84313725, 0.85098039,\n",
              "       0.94509804, 0.25490196, 0.28627451, 0.41568627, 0.45882353,\n",
              "       0.65882353, 0.85882353, 0.86666667, 0.84313725, 0.85098039,\n",
              "       0.8745098 , 0.8745098 , 0.87843137, 0.89803922, 0.11372549,\n",
              "       0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
              "       0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
              "       0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
              "       0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
              "       0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
              "       0.86666667, 0.90196078, 0.2627451 , 0.18823529, 0.79607843,\n",
              "       0.71764706, 0.76078431, 0.83529412, 0.77254902, 0.7254902 ,\n",
              "       0.74509804, 0.76078431, 0.75294118, 0.79215686, 0.83921569,\n",
              "       0.85882353, 0.86666667, 0.8627451 , 0.9254902 , 0.88235294,\n",
              "       0.84705882, 0.78039216, 0.80784314, 0.72941176, 0.70980392,\n",
              "       0.69411765, 0.6745098 , 0.70980392, 0.80392157, 0.80784314,\n",
              "       0.45098039, 0.        , 0.47843137, 0.85882353, 0.75686275,\n",
              "       0.70196078, 0.67058824, 0.71764706, 0.76862745, 0.8       ,\n",
              "       0.82352941, 0.83529412, 0.81176471, 0.82745098, 0.82352941,\n",
              "       0.78431373, 0.76862745, 0.76078431, 0.74901961, 0.76470588,\n",
              "       0.74901961, 0.77647059, 0.75294118, 0.69019608, 0.61176471,\n",
              "       0.65490196, 0.69411765, 0.82352941, 0.36078431, 0.        ,\n",
              "       0.        , 0.29019608, 0.74117647, 0.83137255, 0.74901961,\n",
              "       0.68627451, 0.6745098 , 0.68627451, 0.70980392, 0.7254902 ,\n",
              "       0.7372549 , 0.74117647, 0.7372549 , 0.75686275, 0.77647059,\n",
              "       0.8       , 0.81960784, 0.82352941, 0.82352941, 0.82745098,\n",
              "       0.7372549 , 0.7372549 , 0.76078431, 0.75294118, 0.84705882,\n",
              "       0.66666667, 0.        , 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.25882353, 0.78431373, 0.87058824, 0.92941176,\n",
              "       0.9372549 , 0.94901961, 0.96470588, 0.95294118, 0.95686275,\n",
              "       0.86666667, 0.8627451 , 0.75686275, 0.74901961, 0.70196078,\n",
              "       0.71372549, 0.71372549, 0.70980392, 0.69019608, 0.65098039,\n",
              "       0.65882353, 0.38823529, 0.22745098, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "       0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_duQGtbCTTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mudamos também a dimensão da base de teste\n",
        "X_test = X_test.reshape(-1, 28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Lheay7FSlK",
        "colab_type": "code",
        "outputId": "7bc385d8-4ab3-492d-a348-a828414f3ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5aDsaYSYmXD",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 4: Construindo a Rede Neural Artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l30aZ6-GYtUP",
        "colab_type": "text"
      },
      "source": [
        "### Definindo o modelo\n",
        "\n",
        "Definimos um objeto do tipo Sequential (sequência de camadas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmfogzmn9kqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg8ki6s5Cv5F",
        "colab_type": "code",
        "outputId": "fda931ec-37c5-4c0c-ab4e-95c40b279982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7feba797e898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNzLOAK5Y-mR",
        "colab_type": "text"
      },
      "source": [
        "### Adicionando a primeira camada densa (fully-connected)\n",
        "\n",
        "Hyper-parâmetros da camada:\n",
        "- número de units/neurônios: 128\n",
        "- função de ativação: ReLU\n",
        "- input_shape (camada de entrada): (784, )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBsfDyGE-FX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=512, activation='relu', input_shape=(784, )))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwqx1wZUa1rH",
        "colab_type": "text"
      },
      "source": [
        "### Adicionando Dropout\n",
        "\n",
        "Dropout é uma técnica de regularização na qual alguns neurônios da camada tem seu valor mudado para zero, ou seja, durante o treinamento esses neurônios não serão atualizados. Com isso, temos menos chances de ocorrer overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAmpLPlr-pOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqvyDvNbzwN",
        "colab_type": "text"
      },
      "source": [
        "### Adicionando a camada de saída\n",
        "\n",
        "- units: número de classes (10 na base de dados Fashion MNIST)\n",
        "- função de ativação: softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmkUuF9Y-3mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRsMjsvcOua",
        "colab_type": "text"
      },
      "source": [
        "### Compilando o modelo\n",
        "\n",
        "- Optimizer (otimizador): Adam\n",
        "- Loss (função de erro): Sparse softmax (categorical) crossentropy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbW3xeRK_CrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQOL_EtChrN",
        "colab_type": "code",
        "outputId": "f6799f41-daf9-4461-a62b-e4cafb84ff4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxIIFU1cany",
        "colab_type": "text"
      },
      "source": [
        "### Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-_oLiE0_3A2",
        "colab_type": "code",
        "outputId": "c659e64d-3c6f-47cb-bc1b-d47d4daa3a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.5143 - sparse_categorical_accuracy: 0.8144\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3989 - sparse_categorical_accuracy: 0.8525\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3631 - sparse_categorical_accuracy: 0.8667\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3431 - sparse_categorical_accuracy: 0.8725\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3291 - sparse_categorical_accuracy: 0.8777\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3140 - sparse_categorical_accuracy: 0.8836\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3056 - sparse_categorical_accuracy: 0.8866\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2977 - sparse_categorical_accuracy: 0.8881\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2875 - sparse_categorical_accuracy: 0.8930\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2844 - sparse_categorical_accuracy: 0.8937\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2766 - sparse_categorical_accuracy: 0.8953\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2702 - sparse_categorical_accuracy: 0.8987\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2654 - sparse_categorical_accuracy: 0.9016\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2641 - sparse_categorical_accuracy: 0.9013\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 7s 108us/sample - loss: 0.2568 - sparse_categorical_accuracy: 0.9031\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2516 - sparse_categorical_accuracy: 0.9054\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2457 - sparse_categorical_accuracy: 0.9062\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2437 - sparse_categorical_accuracy: 0.9084\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2413 - sparse_categorical_accuracy: 0.9079\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2405 - sparse_categorical_accuracy: 0.9082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feb92329fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj23nxmtcrhd",
        "colab_type": "text"
      },
      "source": [
        "### Avaliação do modelo e previsão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQCioOmAL7i",
        "colab_type": "code",
        "outputId": "3fc75479-9ea8-4ff2-fe34-5aade77db77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 64us/sample - loss: 0.3515 - sparse_categorical_accuracy: 0.8824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozv2YVlxcx1h",
        "colab_type": "code",
        "outputId": "159ffabc-e31a-4fdf-ccb3-8c71196296d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8823999762535095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvpH8jfvDjAD",
        "colab_type": "code",
        "outputId": "b15af7e1-d592-42bb-ebb5-6ff4a3e306cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35150607060194017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}